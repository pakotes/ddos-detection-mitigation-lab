#!/usr/bin/env python3
"""
Pipeline completo de produ√ß√£o para DDoS Detection
Executa todo o processo: dados reais ‚Üí modelo otimizado ‚Üí valida√ß√£o ‚Üí produ√ß√£o
"""

import logging
import sys
import time
from pathlib import Path
import subprocess
import json

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s:%(name)s:%(message)s'
)
logger = logging.getLogger(__name__)

class ProductionPipeline:
    """Pipeline completo para modelo DDoS de produ√ß√£o"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.scripts_dir = self.project_root / 'deployment' / 'scripts'
        self.models_dir = self.project_root / 'src' / 'models'
        
    def log_step(self, step_name, description):
        """Log formatado para cada etapa"""
        logger.info(f"\n{'='*60}")
        logger.info(f"ETAPA {step_name}: {description}")
        logger.info(f"{'='*60}")
    
    def run_script(self, script_name, description):
        """Executar script Python e verificar resultado"""
        script_path = self.scripts_dir / script_name
        
        if not script_path.exists():
            logger.error(f"Script n√£o encontrado: {script_path}")
            return False
        
        logger.info(f"Executando: {script_name}")
        logger.info(f"Descri√ß√£o: {description}")
        
        try:
            # Executar script
            result = subprocess.run(
                [sys.executable, str(script_path)],
                cwd=str(self.project_root),
                capture_output=True,
                text=True,
                timeout=1800  # 30 minutos timeout
            )
            
            if result.returncode == 0:
                logger.info(f"‚úÖ {script_name} executado com sucesso")
                if result.stdout:
                    # Mostrar apenas √∫ltimas linhas importantes
                    lines = result.stdout.strip().split('\n')
                    for line in lines[-5:]:
                        if line.strip():
                            logger.info(f"  {line}")
                return True
            else:
                logger.error(f"‚ùå Falha em {script_name}")
                if result.stderr:
                    logger.error(f"Erro: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error(f"‚ùå Timeout em {script_name} (30 min)")
            return False
        except Exception as e:
            logger.error(f"‚ùå Erro executando {script_name}: {e}")
            return False
    
    def check_data_availability(self):
        """Verificar se dados est√£o dispon√≠veis"""
        self.log_step("0", "Verifica√ß√£o de Dados")
        
        datasets_dir = self.project_root / 'src' / 'datasets'
        
        # Verificar datasets integrados
        integrated_dir = datasets_dir / 'integrated'
        if integrated_dir.exists():
            files = list(integrated_dir.glob('*.npy'))
            if files:
                logger.info(f"‚úÖ Dados integrados encontrados: {len(files)} arquivos")
                return True
        
        # Verificar dados reais
        real_dir = datasets_dir / 'real'
        if real_dir.exists():
            files = list(real_dir.glob('*.npy'))
            if files:
                logger.info(f"‚úÖ Dados reais encontrados: {len(files)} arquivos")
                return True
        
        logger.warning("‚ö†Ô∏è Nenhum dado encontrado - ser√° necess√°rio processar")
        return False
    
    def process_real_data(self):
        """Processar dados reais se necess√°rio"""
        self.log_step("1", "Processamento de Dados Reais")
        
        # Verificar se dados reais j√° existem
        real_dir = self.project_root / 'src' / 'datasets' / 'real'
        if real_dir.exists() and list(real_dir.glob('*.npy')):
            logger.info("‚úÖ Dados reais j√° processados")
            return True
        
        return self.run_script(
            'process_real_datasets.py',
            'Processamento de CIC-DDoS2019 e UNSW-NB15 originais'
        )
    
    def train_models(self):
        """Treinar modelos com dados reais"""
        self.log_step("2", "Treinamento com Dados Reais")
        
        return self.run_script(
            'train_real_datasets.py',
            'Treinamento com datasets originais'
        )
    
    def validate_models(self):
        """Validar qualidade dos modelos"""
        self.log_step("3", "Valida√ß√£o de Modelos")
        
        # Primeiro tentar valida√ß√£o realista
        realistic_dir = self.models_dir / 'realistic'
        if realistic_dir.exists():
            success = self.run_script(
                'validate_realistic_models.py',
                'Valida√ß√£o de modelos realistas'
            )
            if success:
                return True
        
        # Fallback para valida√ß√£o padr√£o
        return self.run_script(
            'validate_models.py',
            'Valida√ß√£o de modelos padr√£o'
        )
    
    def create_production_model(self):
        """Criar modelo otimizado para produ√ß√£o"""
        self.log_step("4", "Cria√ß√£o do Modelo de Produ√ß√£o")
        
        return self.run_script(
            'create_production_model.py',
            'Cria√ß√£o de modelo otimizado para produ√ß√£o'
        )
    
    def test_production_model(self):
        """Testar modelo de produ√ß√£o"""
        self.log_step("5", "Teste do Modelo de Produ√ß√£o")
        
        success = self.run_script(
            'test_production_model.py',
            'Teste de performance em condi√ß√µes de produ√ß√£o'
        )
        
        if success:
            # Tentar ler relat√≥rio de teste
            report_path = self.models_dir / 'production' / 'production_test_report.json'
            if report_path.exists():
                try:
                    with open(report_path) as f:
                        report = json.load(f)
                    
                    readiness = report.get('production_readiness', {})
                    ready = all(readiness.values())
                    
                    logger.info(f"\nüìä RELAT√ìRIO DE PRODU√á√ÉO:")
                    logger.info(f"  Pronto para produ√ß√£o: {'‚úÖ SIM' if ready else '‚ö†Ô∏è NECESSITA AJUSTES'}")
                    
                    if 'accuracy_test' in report:
                        acc = report['accuracy_test']
                        logger.info(f"  Accuracy: {acc.get('accuracy', 0):.3f}")
                        logger.info(f"  Precision: {acc.get('precision', 0):.3f}")
                        logger.info(f"  Taxa FP: {acc.get('false_positive_rate', 0):.3f}")
                    
                    if 'speed_benchmark' in report:
                        speed = report['speed_benchmark']
                        logger.info(f"  Velocidade: {speed.get('samples_per_second', 0):,.0f} amostras/s")
                    
                except Exception as e:
                    logger.warning(f"Erro lendo relat√≥rio: {e}")
        
        return success
    
    def generate_final_report(self):
        """Gerar relat√≥rio final do pipeline"""
        self.log_step("6", "Relat√≥rio Final")
        
        # Verificar arquivos gerados
        production_dir = self.models_dir / 'production'
        model_file = production_dir / 'ddos_production_model.pkl'
        report_file = production_dir / 'production_test_report.json'
        
        logger.info("üéØ RESULTADOS DO PIPELINE:")
        
        if model_file.exists():
            size_mb = model_file.stat().st_size / (1024 * 1024)
            logger.info(f"  ‚úÖ Modelo de produ√ß√£o: {model_file} ({size_mb:.1f} MB)")
        else:
            logger.error(f"  ‚ùå Modelo de produ√ß√£o n√£o encontrado!")
        
        if report_file.exists():
            logger.info(f"  ‚úÖ Relat√≥rio de teste: {report_file}")
        else:
            logger.warning(f"  ‚ö†Ô∏è Relat√≥rio de teste n√£o encontrado")
        
        # Resumo de modelos dispon√≠veis
        logger.info(f"\nüìÅ MODELOS DISPON√çVEIS:")
        for model_type in ['production', 'realistic', 'hybrid_advanced', 'hybrid']:
            model_dir = self.models_dir / model_type
            if model_dir.exists():
                model_files = list(model_dir.glob('*.pkl'))
                logger.info(f"  {model_type}: {len(model_files)} modelos")
        
        logger.info(f"\nüöÄ COMANDOS √öTEIS:")
        logger.info(f"  Testar modelo: python {self.scripts_dir}/test_production_model.py")
        logger.info(f"  Ver relat√≥rio: cat {report_file}")
        
        return True
    
    def run_complete_pipeline(self, skip_validation=False):
        """Executar pipeline completo"""
        logger.info("üè≠ INICIANDO PIPELINE DE PRODU√á√ÉO DDoS")
        logger.info("="*60)
        
        start_time = time.time()
        
        try:
            # Etapa 0: Verificar dados
            if not self.check_data_availability():
                logger.warning("Dados n√£o encontrados - pipeline processar√° do zero")
            
            # Etapa 1: Processar dados reais
            if not self.process_real_data():
                logger.error("‚ùå Falha no processamento de dados")
                return False
            
            # Etapa 2: Treinar modelos
            if not self.train_models():
                logger.error("‚ùå Falha no treinamento")
                return False
            
            # Etapa 3: Validar (opcional)
            if not skip_validation:
                if not self.validate_models():
                    logger.warning("‚ö†Ô∏è Falha na valida√ß√£o - continuando")
            
            # Etapa 4: Criar modelo de produ√ß√£o
            if not self.create_production_model():
                logger.error("‚ùå Falha na cria√ß√£o do modelo de produ√ß√£o")
                return False
            
            # Etapa 5: Testar modelo de produ√ß√£o
            if not self.test_production_model():
                logger.error("‚ùå Falha no teste de produ√ß√£o")
                return False
            
            # Etapa 6: Relat√≥rio final
            self.generate_final_report()
            
            elapsed = time.time() - start_time
            logger.info(f"\nüéâ PIPELINE CONCLU√çDO COM SUCESSO!")
            logger.info(f"‚è±Ô∏è Tempo total: {elapsed/60:.1f} minutos")
            
            return True
            
        except KeyboardInterrupt:
            logger.warning("‚ùå Pipeline interrompido pelo usu√°rio")
            return False
        except Exception as e:
            logger.error(f"‚ùå Erro no pipeline: {e}")
            return False

def main():
    """Fun√ß√£o principal"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Pipeline de produ√ß√£o DDoS')
    parser.add_argument('--skip-validation', action='store_true',
                       help='Pular etapa de valida√ß√£o')
    parser.add_argument('--step', type=str, choices=[
        'process', 'train', 'validate', 'create', 'test', 'report'
    ], help='Executar apenas uma etapa espec√≠fica')
    
    args = parser.parse_args()
    
    pipeline = ProductionPipeline()
    
    if args.step:
        # Executar etapa espec√≠fica
        if args.step == 'process':
            success = pipeline.process_real_data()
        elif args.step == 'train':
            success = pipeline.train_models()
        elif args.step == 'validate':
            success = pipeline.validate_models()
        elif args.step == 'create':
            success = pipeline.create_production_model()
        elif args.step == 'test':
            success = pipeline.test_production_model()
        elif args.step == 'report':
            success = pipeline.generate_final_report()
    else:
        # Pipeline completo
        success = pipeline.run_complete_pipeline(args.skip_validation)
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
